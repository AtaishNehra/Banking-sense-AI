{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banking Transaction Data - EDA and Preprocessing\n",
    "\n",
    "This notebook provides exploratory data analysis and preprocessing insights for the PaySim banking transaction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure plotting\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw dataset\n",
    "data_path = Path(\"../data/raw/PS_20174392719_1491204439457_log.csv\")\n",
    "\n",
    "if data_path.exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Dataset loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "else:\n",
    "    print(\"Dataset not found. Please run the data download script first.\")\n",
    "    print(\"Run: python data_pipeline/download_data.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "if 'df' in locals():\n",
    "    print(\"Dataset Info:\")\n",
    "    print(f\"Rows: {df.shape[0]:,}\")\n",
    "    print(f\"Columns: {df.shape[1]}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(\"\\nColumn Information:\")\n",
    "    print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "if 'df' in locals():\n",
    "    print(\"First 5 rows:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\nDataset Description:\")\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "if 'df' in locals():\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_percent = (missing_data / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing_data,\n",
    "        'Percentage': missing_percent\n",
    "    }).sort_values('Missing Count', ascending=False)\n",
    "    \n",
    "    print(\"Missing Values Summary:\")\n",
    "    display(missing_df[missing_df['Missing Count'] > 0])\n",
    "    \n",
    "    if missing_df['Missing Count'].sum() == 0:\n",
    "        print(\"âœ“ No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and unique values\n",
    "if 'df' in locals():\n",
    "    print(\"Data Types and Unique Values:\")\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        unique_count = df[col].nunique()\n",
    "        print(f\"{col:15} | {str(dtype):10} | {unique_count:,} unique values\")\n",
    "        \n",
    "        # Show unique values for categorical columns\n",
    "        if dtype == 'object' and unique_count < 20:\n",
    "            print(f\"    Values: {df[col].unique()}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fraud Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud distribution analysis\n",
    "if 'df' in locals() and 'isFraud' in df.columns:\n",
    "    fraud_counts = df['isFraud'].value_counts()\n",
    "    fraud_rate = df['isFraud'].mean()\n",
    "    \n",
    "    print(f\"Fraud Distribution:\")\n",
    "    print(f\"Not Fraud: {fraud_counts[0]:,} ({(1-fraud_rate)*100:.2f}%)\")\n",
    "    print(f\"Fraud: {fraud_counts[1]:,} ({fraud_rate*100:.2f}%)\")\n",
    "    print(f\"\\nFraud Rate: {fraud_rate:.4f}\")\n",
    "    \n",
    "    # Visualize fraud distribution\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Bar chart\n",
    "    fraud_counts.plot(kind='bar', ax=ax1, color=['skyblue', 'coral'])\n",
    "    ax1.set_title('Fraud vs. Legitimate Transactions (Count)')\n",
    "    ax1.set_xlabel('Transaction Type')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_xticklabels(['Legitimate', 'Fraud'], rotation=0)\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for i, v in enumerate(fraud_counts.values):\n",
    "        ax1.text(i, v + max(fraud_counts.values) * 0.01, f'{v:,}', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Pie chart\n",
    "    ax2.pie(fraud_counts.values, labels=['Legitimate', 'Fraud'], \n",
    "            colors=['skyblue', 'coral'], autopct='%1.2f%%', startangle=90)\n",
    "    ax2.set_title('Fraud Distribution (Percentage)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nClass Imbalance Ratio: {fraud_counts[0]/fraud_counts[1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transaction Amount Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount distribution analysis\n",
    "if 'df' in locals() and 'amount' in df.columns:\n",
    "    print(\"Transaction Amount Statistics:\")\n",
    "    print(df['amount'].describe())\n",
    "    \n",
    "    # Create amount distribution plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Histogram of amounts\n",
    "    df['amount'].hist(bins=50, ax=axes[0,0], color='skyblue', alpha=0.7)\n",
    "    axes[0,0].set_title('Distribution of Transaction Amounts')\n",
    "    axes[0,0].set_xlabel('Amount')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].axvline(df['amount'].mean(), color='red', linestyle='--', \n",
    "                      label=f'Mean: ${df[\"amount\"].mean():,.2f}')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # Log-scale histogram\n",
    "    df[df['amount'] > 0]['amount'].apply(np.log10).hist(bins=50, ax=axes[0,1], \n",
    "                                                        color='lightgreen', alpha=0.7)\n",
    "    axes[0,1].set_title('Distribution of Transaction Amounts (Log Scale)')\n",
    "    axes[0,1].set_xlabel('Log10(Amount)')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Box plot by fraud status\n",
    "    if 'isFraud' in df.columns:\n",
    "        df.boxplot(column='amount', by='isFraud', ax=axes[1,0])\n",
    "        axes[1,0].set_title('Transaction Amounts by Fraud Status')\n",
    "        axes[1,0].set_xlabel('Is Fraud')\n",
    "        axes[1,0].set_ylabel('Amount')\n",
    "        \n",
    "        # Comparison of fraud vs legitimate amounts\n",
    "        fraud_amounts = df[df['isFraud'] == 1]['amount']\n",
    "        legit_amounts = df[df['isFraud'] == 0]['amount']\n",
    "        \n",
    "        axes[1,1].hist([legit_amounts, fraud_amounts], bins=50, alpha=0.7, \n",
    "                       label=['Legitimate', 'Fraud'], color=['skyblue', 'coral'])\n",
    "        axes[1,1].set_title('Amount Distribution: Fraud vs Legitimate')\n",
    "        axes[1,1].set_xlabel('Amount')\n",
    "        axes[1,1].set_ylabel('Frequency')\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transaction Type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction type analysis\n",
    "if 'df' in locals() and 'type' in df.columns:\n",
    "    type_counts = df['type'].value_counts()\n",
    "    \n",
    "    print(\"Transaction Type Distribution:\")\n",
    "    for tx_type, count in type_counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"{tx_type:12}: {count:,} ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Visualize transaction types\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Bar chart of transaction types\n",
    "    type_counts.plot(kind='bar', ax=ax1, color='lightblue')\n",
    "    ax1.set_title('Transaction Types Distribution')\n",
    "    ax1.set_xlabel('Transaction Type')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, v in enumerate(type_counts.values):\n",
    "        ax1.text(i, v + max(type_counts.values) * 0.01, f'{v:,}', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Fraud rate by transaction type\n",
    "    if 'isFraud' in df.columns:\n",
    "        fraud_by_type = df.groupby('type')['isFraud'].agg(['count', 'sum', 'mean'])\n",
    "        fraud_by_type.columns = ['Total', 'Fraud_Count', 'Fraud_Rate']\n",
    "        \n",
    "        print(\"\\nFraud Rate by Transaction Type:\")\n",
    "        display(fraud_by_type)\n",
    "        \n",
    "        fraud_by_type['Fraud_Rate'].plot(kind='bar', ax=ax2, color='coral')\n",
    "        ax2.set_title('Fraud Rate by Transaction Type')\n",
    "        ax2.set_xlabel('Transaction Type')\n",
    "        ax2.set_ylabel('Fraud Rate')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, v in enumerate(fraud_by_type['Fraud_Rate'].values):\n",
    "            ax2.text(i, v + max(fraud_by_type['Fraud_Rate'].values) * 0.01, \n",
    "                    f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis of numerical features\n",
    "if 'df' in locals():\n",
    "    # Select numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    if len(numerical_cols) > 1:\n",
    "        # Calculate correlation matrix\n",
    "        correlation_matrix = df[numerical_cols].corr()\n",
    "        \n",
    "        # Create correlation heatmap\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "        \n",
    "        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', \n",
    "                    center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\": .5})\n",
    "        plt.title('Correlation Matrix of Numerical Features')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Show strongest correlations with fraud (if exists)\n",
    "        if 'isFraud' in numerical_cols:\n",
    "            fraud_correlations = correlation_matrix['isFraud'].abs().sort_values(ascending=False)\n",
    "            fraud_correlations = fraud_correlations[fraud_correlations.index != 'isFraud']\n",
    "            \n",
    "            print(\"\\nStrongest correlations with fraud:\")\n",
    "            for feature, corr in fraud_correlations.head(10).items():\n",
    "                direction = \"positive\" if correlation_matrix.loc['isFraud', feature] > 0 else \"negative\"\n",
    "                print(f\"{feature:20}: {corr:.4f} ({direction})\")\n",
    "    else:\n",
    "        print(\"Not enough numerical columns for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Balance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance analysis (if balance columns exist)\n",
    "if 'df' in locals():\n",
    "    balance_cols = [col for col in df.columns if 'balance' in col.lower()]\n",
    "    \n",
    "    if balance_cols:\n",
    "        print(f\"Balance columns found: {balance_cols}\")\n",
    "        \n",
    "        # Calculate balance changes\n",
    "        if 'oldbalanceOrg' in df.columns and 'newbalanceOrig' in df.columns:\n",
    "            df['balance_change_orig'] = df['newbalanceOrig'] - df['oldbalanceOrg']\n",
    "            \n",
    "        if 'oldbalanceDest' in df.columns and 'newbalanceDest' in df.columns:\n",
    "            df['balance_change_dest'] = df['newbalanceDest'] - df['oldbalanceDest']\n",
    "        \n",
    "        # Plot balance distributions\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        if 'oldbalanceOrg' in df.columns:\n",
    "            df['oldbalanceOrg'].hist(bins=50, ax=axes[0,0], alpha=0.7, color='lightblue')\n",
    "            axes[0,0].set_title('Original Balance Distribution (Origin)')\n",
    "            axes[0,0].set_xlabel('Balance')\n",
    "            axes[0,0].set_ylabel('Frequency')\n",
    "        \n",
    "        if 'oldbalanceDest' in df.columns:\n",
    "            df['oldbalanceDest'].hist(bins=50, ax=axes[0,1], alpha=0.7, color='lightgreen')\n",
    "            axes[0,1].set_title('Original Balance Distribution (Destination)')\n",
    "            axes[0,1].set_xlabel('Balance')\n",
    "            axes[0,1].set_ylabel('Frequency')\n",
    "        \n",
    "        if 'balance_change_orig' in df.columns:\n",
    "            df['balance_change_orig'].hist(bins=50, ax=axes[1,0], alpha=0.7, color='coral')\n",
    "            axes[1,0].set_title('Balance Change Distribution (Origin)')\n",
    "            axes[1,0].set_xlabel('Balance Change')\n",
    "            axes[1,0].set_ylabel('Frequency')\n",
    "        \n",
    "        if 'balance_change_dest' in df.columns:\n",
    "            df['balance_change_dest'].hist(bins=50, ax=axes[1,1], alpha=0.7, color='gold')\n",
    "            axes[1,1].set_title('Balance Change Distribution (Destination)')\n",
    "            axes[1,1].set_xlabel('Balance Change')\n",
    "            axes[1,1].set_ylabel('Frequency')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No balance columns found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Time-based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based analysis (if step column exists)\n",
    "if 'df' in locals() and 'step' in df.columns:\n",
    "    # Convert step to hours and days\n",
    "    df['hour'] = df['step'] % 24\n",
    "    df['day'] = df['step'] // 24\n",
    "    \n",
    "    print(f\"Time range: Step {df['step'].min()} to {df['step'].max()}\")\n",
    "    print(f\"Equivalent to {df['day'].max() + 1} days\")\n",
    "    \n",
    "    # Plot time-based patterns\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Transactions by hour\n",
    "    hourly_counts = df['hour'].value_counts().sort_index()\n",
    "    hourly_counts.plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "    axes[0,0].set_title('Transactions by Hour of Day')\n",
    "    axes[0,0].set_xlabel('Hour')\n",
    "    axes[0,0].set_ylabel('Count')\n",
    "    \n",
    "    # Transactions by day\n",
    "    daily_counts = df['day'].value_counts().sort_index()\n",
    "    daily_counts.plot(ax=axes[0,1], color='lightgreen')\n",
    "    axes[0,1].set_title('Transactions by Day')\n",
    "    axes[0,1].set_xlabel('Day')\n",
    "    axes[0,1].set_ylabel('Count')\n",
    "    \n",
    "    # Fraud by hour (if fraud column exists)\n",
    "    if 'isFraud' in df.columns:\n",
    "        fraud_by_hour = df.groupby('hour')['isFraud'].mean()\n",
    "        fraud_by_hour.plot(kind='bar', ax=axes[1,0], color='coral')\n",
    "        axes[1,0].set_title('Fraud Rate by Hour of Day')\n",
    "        axes[1,0].set_xlabel('Hour')\n",
    "        axes[1,0].set_ylabel('Fraud Rate')\n",
    "        \n",
    "        # Fraud by day\n",
    "        fraud_by_day = df.groupby('day')['isFraud'].mean()\n",
    "        fraud_by_day.plot(ax=axes[1,1], color='orange')\n",
    "        axes[1,1].set_title('Fraud Rate by Day')\n",
    "        axes[1,1].set_xlabel('Day')\n",
    "        axes[1,1].set_ylabel('Fraud Rate')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No time column ('step') found for temporal analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Customer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer-level analysis\n",
    "if 'df' in locals() and 'nameOrig' in df.columns:\n",
    "    # Customer transaction statistics\n",
    "    customer_stats = df.groupby('nameOrig').agg({\n",
    "        'amount': ['count', 'sum', 'mean', 'std'],\n",
    "        'isFraud': 'sum' if 'isFraud' in df.columns else 'count'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    customer_stats.columns = ['_'.join(col).strip() for col in customer_stats.columns]\n",
    "    customer_stats = customer_stats.reset_index()\n",
    "    \n",
    "    print(f\"Number of unique customers: {df['nameOrig'].nunique():,}\")\n",
    "    print(f\"Average transactions per customer: {df.groupby('nameOrig').size().mean():.2f}\")\n",
    "    \n",
    "    # Plot customer activity distribution\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Transactions per customer\n",
    "    transactions_per_customer = df.groupby('nameOrig').size()\n",
    "    transactions_per_customer.hist(bins=50, ax=ax1, alpha=0.7, color='lightblue')\n",
    "    ax1.set_title('Distribution of Transactions per Customer')\n",
    "    ax1.set_xlabel('Number of Transactions')\n",
    "    ax1.set_ylabel('Number of Customers')\n",
    "    ax1.axvline(transactions_per_customer.mean(), color='red', linestyle='--', \n",
    "               label=f'Mean: {transactions_per_customer.mean():.2f}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Total amount per customer\n",
    "    amount_per_customer = df.groupby('nameOrig')['amount'].sum()\n",
    "    amount_per_customer.hist(bins=50, ax=ax2, alpha=0.7, color='lightgreen')\n",
    "    ax2.set_title('Distribution of Total Amount per Customer')\n",
    "    ax2.set_xlabel('Total Transaction Amount')\n",
    "    ax2.set_ylabel('Number of Customers')\n",
    "    ax2.axvline(amount_per_customer.mean(), color='red', linestyle='--', \n",
    "               label=f'Mean: ${amount_per_customer.mean():,.2f}')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Top customers by transaction volume\n",
    "    print(\"\\nTop 10 customers by transaction count:\")\n",
    "    top_customers = transactions_per_customer.sort_values(ascending=False).head(10)\n",
    "    for customer, count in top_customers.items():\n",
    "        total_amount = amount_per_customer[customer]\n",
    "        print(f\"{customer}: {count} transactions, ${total_amount:,.2f} total\")\n",
    "else:\n",
    "    print(\"No customer identifier column ('nameOrig') found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data for comparison (if available)\n",
    "processed_path = Path(\"../data/processed/transactions_processed.csv\")\n",
    "\n",
    "if processed_path.exists():\n",
    "    df_processed = pd.read_csv(processed_path)\n",
    "    \n",
    "    print(\"Preprocessing Comparison:\")\n",
    "    print(f\"Raw data shape: {df.shape if 'df' in locals() else 'N/A'}\")\n",
    "    print(f\"Processed data shape: {df_processed.shape}\")\n",
    "    \n",
    "    if 'df' in locals():\n",
    "        print(f\"\\nColumns added during preprocessing: {set(df_processed.columns) - set(df.columns)}\")\n",
    "        print(f\"Columns removed during preprocessing: {set(df.columns) - set(df_processed.columns)}\")\n",
    "    \n",
    "    # Show sample of processed features\n",
    "    print(\"\\nSample of processed data:\")\n",
    "    display(df_processed.head())\n",
    "    \n",
    "    # Feature correlation in processed data\n",
    "    if 'isFraud' in df_processed.columns:\n",
    "        numerical_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
    "        correlations = df_processed[numerical_cols].corr()['isFraud'].abs().sort_values(ascending=False)\n",
    "        \n",
    "        print(\"\\nTop 10 features correlated with fraud (processed data):\")\n",
    "        for feature, corr in correlations[1:11].items():  # Skip isFraud itself\n",
    "            print(f\"{feature:25}: {corr:.4f}\")\nelse:\n    print(\"Processed data not found. Run preprocessing first:\")\n    print(\"python data_pipeline/preprocess.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Recommendations for ML Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling recommendations based on EDA\n",
    "print(\"=\" * 60)\n",
    "print(\"RECOMMENDATIONS FOR ML MODELING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'df' in locals():\n",
    "    if 'isFraud' in df.columns:\n",
    "        fraud_rate = df['isFraud'].mean()\n",
    "        imbalance_ratio = (1 - fraud_rate) / fraud_rate\n",
    "        \n",
    "        print(f\"\\n1. CLASS IMBALANCE:\")\n",
    "        print(f\"   - Fraud rate: {fraud_rate:.4f} ({fraud_rate*100:.2f}%)\")\n",
    "        print(f\"   - Imbalance ratio: {imbalance_ratio:.1f}:1\")\n",
    "        \n",
    "        if imbalance_ratio > 10:\n",
    "            print(f\"   - Recommendation: Use stratified sampling, SMOTE, or class weights\")\n",
    "            print(f\"   - Consider ensemble methods like XGBoost with scale_pos_weight\")\n",
    "        \n",
    "    print(f\"\\n2. FEATURE ENGINEERING:\")\n",
    "    if 'amount' in df.columns:\n",
    "        print(f\"   - Log-transform amount due to right skewness\")\n",
    "        print(f\"   - Create amount bins/categories\")\n",
    "    \n",
    "    if 'step' in df.columns:\n",
    "        print(f\"   - Extract hour and day features from step\")\n",
    "        print(f\"   - Create time-based aggregations\")\n",
    "    \n",
    "    if 'nameOrig' in df.columns:\n",
    "        print(f\"   - Create customer-level features (transaction count, frequency)\")\n",
    "        print(f\"   - Rolling window features for customer behavior\")\n",
    "    \n",
    "    balance_cols = [col for col in df.columns if 'balance' in col.lower()]\n",
    "    if len(balance_cols) >= 2:\n",
    "        print(f\"   - Calculate balance changes and ratios\")\n",
    "    \n",
    "    print(f\"\\n3. MODEL SELECTION:\")\n",
    "    print(f\"   - Primary: XGBoost (handles imbalance, feature interactions)\")\n",
    "    print(f\"   - Alternative: Random Forest, LightGBM\")\n",
    "    print(f\"   - Consider ensemble of multiple algorithms\")\n",
    "    \n",
    "    print(f\"\\n4. EVALUATION METRICS:\")\n",
    "    print(f\"   - Primary: AUC-ROC, Precision-Recall AUC\")\n",
    "    print(f\"   - Secondary: F1-score, Recall (for fraud detection)\")\n",
    "    print(f\"   - Avoid accuracy due to class imbalance\")\n",
    "    \n",
    "    print(f\"\\n5. CROSS-VALIDATION:\")\n",
    "    print(f\"   - Use stratified k-fold to maintain class distribution\")\n",
    "    print(f\"   - Consider time-based splits if temporal patterns matter\")\n",
    "    \n",
    "    if 'type' in df.columns:\n",
    "        fraud_by_type = df.groupby('type')['isFraud'].mean()\n",
    "        high_fraud_types = fraud_by_type[fraud_by_type > fraud_rate * 2].index.tolist()\n",
    "        if high_fraud_types:\n",
    "            print(f\"\\n6. TRANSACTION TYPE INSIGHTS:\")\n",
    "            print(f\"   - High-risk types: {high_fraud_types}\")\n",
    "            print(f\"   - Consider type-specific models or features\")\nelse:\n    print(\"No data available for recommendations. Please load the dataset first.\")\n\nprint(f\"\\n{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
